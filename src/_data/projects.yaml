- title: Programmable RDMA
  is_ongoing: true
  participants: New project led by Emmanuel Amaro
  desc: >
    We propose extensions to RDMA called Remote Memory Calls (RMCs) that allows applications to 
    install a customized set of 1-sided RDMA operations. We are exploring how can RMCs be implemented 
    on the forthcoming generation of SmartNICs, and we will compare its performance to pure 1-sided and 2-sided 
    RDMA operations.
  feature_excerpt: >
    We propose extensions to RDMA called Remote Memory Calls (RMCs) that allows applications to 
    install a customized set of 1-sided RDMA operations. We are exploring how can RMCs be implemented 
    on the forthcoming generation of SmartNICs, and we will compare its performance to pure 1-sided and 2-sided 
    RDMA operations.

- title: CESSNA
  is_ongoing: true
  participants: Ongoing project by Aisha Mushtaq, Yotam Harchol, Vivian Fang, Murphy McCauley, Aurojit Panda, Scott Shenker
  desc: >
    The introduction of computational resources at the network edge allows application designers 
    to offload computation from clients and/or servers, thereby reducing response latency and 
    backbone bandwidth. More fundamentally, edge-computing moves applications from a client-server 
    model to a client-edge-server model. While this is an attractive paradigm for many use cases, 
    it raises the question of how to design client-edge-server systems so they can tolerate edge 
    failures and client mobility. This is particularly challenging when edge processing is strongly 
    stateful. In this work we propose a design for meeting this challenge called the Client-Edge-Server 
    for Stateful Network Applications (CESSNA).
  feature_excerpt: >
    The introduction of computational resources at the network edge allows application designers 
    to offload computation from clients and/or servers. We propose a design called the Client-Edge-Server 
    for Stateful Network Applications (CESSNA) for client-edge-server systems so they can tolerate 
    edge failures and client mobility.

- title: μTelco
  is_ongoing: true
  participants: New project led by Zhihong Luo
  desc: >
    Today’s cellular network architecture and its business model are driven by the presence of monopoly, 
    which causes high barrier-to-entry for small network operators, excessively complicated spec and difficulty 
    in extending network coverage. We propose μTCell architecture to address these issues by federating 
    cellular network among a large number of μTelcos.
  feature_excerpt: >
    Today’s cellular network architecture and its business model are driven by the presence of monopoly. 
    We propose μTCell architecture to address these issues by federating cellular network among a 
    large number of μTelcos.

- title: Efficient Work Stealing
  is_ongoing: true
  participants: Early project led by Amy Ousterhout
  desc: >
    Datacenter servers must balance load across many (sometimes dozens) of cores. 
    Existing techniques such as work stealing perform well for long tasks, but can be inefficient for short tasks 
    that take only a couple of microseconds. At these timescales, cores may spend a significant fraction of their 
    time just looking for work, rather than actually doing useful work; this wastes CPU resources that could be 
    used by other applications on the same server. We are exploring techniques to perform load balancing more 
    efficiently, so that requests are handled faster and cores waste fewer cycles looking for work. 
  feature_excerpt: >
    Existing techniques such as work stealing perform well for long tasks, but can be inefficient for short tasks 
    that take only a couple of microseconds. We explore techniques to perform load balancing more efficiently, 
    so that requests are handled faster and cores waste fewer cycles looking for work. 

- title: Kappa
  url: "https://kappa.cs.berkeley.edu/"
  is_ongoing: true
  participants: Wen Zhang, Vivian Fang, Aurojit Panda, Scott Shenker
  desc: >
    Serverless computing (e.g., AWS Lambda) was initially designed for event-driven applications, 
    where each event handler is guaranteed to complete within a limited time duration. Kappa aims 
    to enable general purpose, parallel computation on serverless platforms. To do this, Kappa 
    provides a continuation-based checkpointing mechanism that allows long-running computations on 
    time-bounded lambda functions; and, a message-passing concurrency API for easily expressing 
    parallelism and exploiting the elasticity of serverless platforms.
  links:
    - {
        name: Source Code,
        url: "https://github.com/NetSys/kappa",
        type: code,
        featured: true,
    }

- title: Automating GDPR
  is_ongoing: true
  participants: New project by Michael Alan Chang, Wen Zhang, Eric Sheng, Aurojit Panda, Scott Shenker
  desc: >
    Recent Data Privacy Acts like GDPR and CCPA necessitate well-defined data APIs between data 
    security/privacy personnel and application developers. However, poor data governance in Kubernetes 
    applications poses a major obstacle towards developing this API. Data tends to be disorganized, 
    decentralized, and redundant, and is stored under different names over different databases, views, 
    tables -- all of which are constantly being changed. Thus, tracking and controlling application-wide 
    data flow is currently impossible. We have developed a network control plane for data 
    that provides developer with a centralized interface to enforce policy around data. 
    Moreover, we have developed the theoretical foundations to formally guarantee that incoming 
    queries are compliant with the operator-specified policies.
  feature_excerpt: >
    We developed a network control plane for data that provides developer with a centralized interface to enforce policy around data. 
    We also built theoretical foundations to formally guarantee that incoming queries are compliant with the operator-specified policies.

- title: RCS
  is_ongoing: true
  participants: New project by Lloyd Brown, Arvind Krishnamurth (UW), Ganesh Ananthanarayanan (MSR), Ethan Katz Basset (Columbia), Sylvia Ratnasamy, Scott Shenker
  desc: >
    The conventional wisdom requires that all congestion control algorithms deployed on the public Internet be TCP-friendly. 
    If universally obeyed, this requirement would greatly constrain the future of such congestion control algorithms. 
    If partially ignored, as is increasingly likely, then there could be significant inequities in the bandwidth 
    received by different flows. To avoid this dilemma, we propose an alternative to the TCP-friendly paradigm 
    that can accommodate innovation, is consistent with the Internet’s current economic model, and is feasible 
    to deploy given current usage trends.
  feature_excerpt: >
    The conventional wisdom requires that all congestion control algorithms deployed on the public Internet be TCP-friendly.
    We propose an alternative to the TCP-friendly paradigm that can accommodate innovation, is consistent with the Internet’s 
    current economic model, and is feasible to deploy given current usage trends.

- title: Autotune
  is_ongoing: true
  participants: Ongoing project by Michael Alan Chang, Will Wang, Aurojit Panda, Scott Shenker
  desc: >
    Most large web-scale applications are now built by composing collections (up to 100s or 1000s) of microservices. 
    Operators need to decide how many resources are allocated to each microservice, and these allocations can have a 
    large impact on application performance. Manually determining allocations that are both cost-efficient and 
    meet performance requirements is challenging, even for experienced operators. In this paper we present 
    Autotune, an end-to-end tool that automatically minimizes resource utilization while maintaining good application performance.

- title: Persimmon
  is_ongoing: true
  participants: Wen Zhang, Scott Shenker, Irene Zhang
  desc: >
    Distributed in-memory storage systems are crucial for meeting the low latency
    requirements of modern datacenter services. However, they lose all state on
    failure, so recovery is expensive and data loss is always a risk.  The
    Persimmon system leverages persistent memory (PM) to convert existing in-memory
    storage systems into persistent, crash-consistent versions with low overhead
    and minimal code changes. Persimmon offers a simple Persistent State Machine
    abstraction for PM and implements persistence through operation logging on the
    critical path and a novel crash-consistent shadow execution technique for log
    digestion in the background.
  feature_excerpt: >
    Distributed in-memory storage systems lose all state on failure, so recovery is expensive and data loss is always a risk.
    The Persimmon system leverages persistent memory (PM) to convert existing in-memory storage systems into persistent, 
    crash-consistent versions with low overhead and minimal code changes. 

- title: CFM
  url: "https://github.com/clusterfarmem"
  is_ongoing: true
  participants: Emmanuel Amaro, Christopher Branner-Augmon, Zhihong Luo, Amy Ousterhout, Marcos K. Aguilera, Aurojit Panda, Sylvia Ratnasamy, Scott Shenker
  desc: >
    As memory requirements grow, and advances in memory technology slow, the availability of sufficient 
    main memory is increasingly the bottleneck in large compute clusters. One solution to this is memory 
    disaggregation, where jobs can remotely access memory on other servers, or far memory. This project 
    presents a faster swapping mechanism and a far memory-aware cluster scheduler that make it possible 
    to support far memory at rack scale. While far memory is not a panacea, for memory-intensive workloads, 
    CFM can provide performance improvements on the order of 10% or more even without changing the total 
    amount of memory available.
  links:
    - {
        name: Source Code,
        url: "https://github.com/clusterfarmem",
        type: code,
        featured: true,
    }
    - {
        name: "Paper",
        url: "https://dl.acm.org/doi/abs/10.1145/3342195.3387522",
        type: paper,
        featured: true
    }

- title: OS for the Modern Age
  is_ongoing: true
  participants: Early project led by Murphy McCauley
  desc: >
     This NetSys project attempts to rethink foundational aspects of operating system design for 
     servers in the modern age, confronting issues such as changing performance bottlenecks (e.g., due 
     to vast performance changes in underlying technologies like networks and storage), the central 
     importance of isolation (in the sense of performance, data, and metadata), and shifting workloads 
     (such as extremely short and varied edge workloads).

- title: Routing Resilience
  is_ongoing: true
  participants: Ongoing project led by Murphy McCauley
  desc: >
    A project in this area attempts to deliver a routing resiliency mechanism that is easily 
    implementable, easily deployable, and easily manageable while offering packet delivery rates 
    that rival those of the most sophisticated resiliency mechanisms.
  feature_excerpt: >
    A project in this area attempts to deliver a routing resiliency mechanism that is easily implementable, 
    easily deployable, and easily manageable while offering packet delivery rates that rival those of 
    the most sophisticated resiliency mechanisms.

- title: Edgy
  is_ongoing: true
  participants: Ongoing project by John Westhoff, Aisha Mushtaq, Amir Shahatit, Yotam Harchol, Aurojit Panda, Scott Shenker
  desc: >
    In the last few years there has been increased interest in deploying application logic at the network edge.  
    However, in order to effectively use edge resources, applications must replicate state at edges. In current 
    applications the policy for when and where state should be replicated is embedded in the application, 
    however this policy depends not just on application logic but also on workloads and resource availability. 
    Workload and resource availability can vary significantly over an application's lifetime, and this can result 
    in poor performance when adopting edge computing. In this work we propose Edgy, a framework that decouples 
    replication logic from application logic, thus enabling applications to better respond to workload and 
    infrastructure changes.
  feature_excerpt: >
    We propose Edgy, a framework that decouples replication logic from application logic, 
    thus enabling applications to better respond to workload and infrastructure changes.

- title: Enabling a Permanent Revolution in Internet Architecture
  is_ongoing: false
  participants: James Murphy McCauley, Yotam Harchol, Aurojit Panda, Barath Raghavan, Scott Shenker
  desc: >
    The research community has developed a number of interesting proposals for new Internet architectures 
    (e.g., NDN and XIA), which sometimes leads to asking the high stakes question of which one of these 
    new proposals should succeed the current Internet architecture. This project, presented at SIGCOMM 2019 
    as "Enabling a Permanent Revolution in Internet Architecture", explored a vision for the future wherein 
    multiple Internet architectures can be deployed on and coexist on the same existing infrastructure. The 
    proposed design radically reduces the requirements for deploying a new architecture (i.e., it doesn't 
    require replacing every router in the world), and removes the requirement that a single architectural 
    design must meet everyone's needs.
  links:
    - {
        name: "SIGCOMM Paper",
        url: "https://dl.acm.org/doi/10.1145/3341302.3342075",
        type: paper,
        featured: true
    }

- title: Network Evolution for DNNs
  is_ongoing: false
  participants:  Michael Alan Chang, Aurojit Panda, Scott Shenker
  desc: >
    Deep Neural Networks increasingly power applications like image search, voice recognition, autonomous vehicles, 
    spam detection, datacenter power management, etc. Many of these applications require DNNs to be periodically retrained, 
    thereby improving prediction quality. As a result improving DNN training time has a significant impact on application performance. 
    As a result DNN training is increasingly distributed across machines, and executed on GPUs, ASICs, or other specialized hardware. 
    In this paper we analyze how the network fabric impacts DNN training time in order to determine how the network fabric should 
    change to better accommodate these jobs. We rely on analytical models and trace driven simulation for our analysis and find 
    that changing the network fabric can significantly impact DNN training performance, but unlike traditional data parallel systems 
    the biggest improvements come from improving data distribution mechanisms rather than aggregation mechanisms.
  inks:
    - {
        name: SysML Paper,
        url: "https://arxiv.org/abs/2004.10275",
        type: paper,
        featured: true,
    }

- title: Savanna
  is_ongoing: true
  participants: Ongoing project by Lloyd Brown, Peter Gao, Ed Oakes, Wen Zhang, Aurojit Panda, Sylvia Ratnasamy, Scott Shenker
  desc: >
    Serverless computing is a relatively recent cloud computing paradigm that allows customers 
    to write lightweight, short-lived functions that are executed on resources provisioned and managed by 
    cloud providers. This architecture was originally designed to simplify stateless, event-driven applications 
    such as those designed to handle web requests, compress images, or generate thumbnails. However, 
    this paradigm has been increasingly adopted in other domains including data analytics, machine learning, 
    and sensor data processing. These domains, and other potential applications, could benefit from better 
    fault-tolerance, consistent concurrent file access, and improved I/O performance than are provided by 
    current serverless offerings. In this paper we propose Savanna, a system that implements these features 
    for serverless applications. Savanna requires applications to use a file API, but is otherwise transparent 
    to serverless applications.

- title: Predicting System Performance
  is_ongoing: true
  participants: Silvery Fu, Aditya Srivastava, Saurabh Gupta, Radhika Mittal, Sylvia Ratnasamy
  desc: >
    The ability to predict system performance is key to enabling better system optimization and planning. 
    Given recent advances in Machine learning (ML), one might 
    ask whether ML is a natural fit for this task. We study whether and how ML 
    can be used to predict performance. Our findings reveal that the performance variability
    stemming from optimization or randomization techniques in many applications makes performance 
    prediction inherently difficult, i.e. in such cases, no ML technique can predict performance 
    with high enough accuracy. We show how eliminating the discovered sources of variability 
    greatly improves prediction accuracy. Since it is difficult to eliminate all possible sources of 
    system performance variability, we further discuss how ML models can be extended to cope with them
    by learning a distribution as opposed to point estimates.

- title: BESS
  is_ongoing: false
  participants: Sangjin Han, Keon Jang, Dongsu Han, Sylvia Ratnasamy
  desc: >
    Modern NICs implement various features in hardware, such as protocol
    offloading, multicore supports, traffic control, and self virtualization. This
    approach exposes several issues: protocol dependence, limited hardware resources,
    and incomplete/buggy/non-compliant implementation. Even worse, the slow
    evolution of hardware NICs due to increasingly overwhelming design
    complexity cannot keep up in time with the new protocols and rapidly
    changing network architectures. We introduce the SoftNIC architecture to
    fill the gap between hardware capabilities and user demands. Our current
    SoftNIC prototype implements sophisticated NIC features on a few dedicated
    processor cores, while assuming only streamlined functionalities in
    hardware. The preliminary evaluation results show that most NIC features can
    be implemented in software with minimum performance cost, while the
    flexibility of software provides further potential benefits.
  feature_excerpt: >
    BESS is a modular framework for software switches. BESS is neither
    pre-configured or hardcoded to perform particular functionality. Instead, you
    can configure your own packet processing datapath by composing small modules.
  links:
    - {
        name: "Paper",
        url: "http://www.eecs.berkeley.edu/Pubs/TechRpts/2015/EECS-2015-155.pdf",
        type: paper,
        featured: true
    }
    - {
        name: "Source Code",
        url: "https://github.com/NetSys/bess",
        type: code,
        featured: true
    }

- title: E2
  url: "/projects/e2.html"
  is_ongoing: false
  participants: Shoumik Palkar, Chang Lan, Sangjin Han, Keon Jang, Aurojit Panda,
    Melvin Walls, Christian Maciocco, Sylvia Ratnasamy, Joshua Reich,
    Luigi Rizzo, Scott Shenker
  desc: >
    By moving network appliance functionality from proprietary hardware to software,
    Network Function Virtualization promises to bring the advantages of cloud
    computing to network packet processing. However, the evolution of cloud
    computing (particularly for data analytics) has greatly benefited from
    application-independent methods for scaling and placement that achieve high
    efficiency while relieving programmers of these burdens. NFV has no such general
    management solutions. To this end, we present E2 -- a scalable and
    application-agnostic scheduling framework for packet processing.
  links:
    - {
        name: SOSP Paper,
        url: https://people.eecs.berkeley.edu/~sylvia/cs268-2016/papers/e2.pdf,
        type: paper,
        featured: true
    }
    - {
        name: Slides,
        url: /static/slides/IEEE-NFV2015-final.pptx,
        type: slides
    }
    - {
        name: Source Code,
        url: "https://github.com/NetSys/e2",
        type: code,
    }

- title: NetBricks
  is_ongoing: false
  participants: Aurojit Panda, Sangjin Han, Keon Jang, Melvin Walls,
    Sylvia Ratnasamy, Scott Shenker
  desc: >
    The move from hardware middleboxes to software net-work functions, as
    advocated by NFV, has proven morechallenging than expected. Developing new NFs
    remains a tedious process, with developers frequently having to re-discover and
    reapply the same set of optimizations, while current techniques for safely
    running multiple NFs (using VMs or containers) incur high performance overheads.
    In this paper we describe NetBricks, a new NFV framework that aims to improve both
    the building and running of NFs. For building NFs we take inspiration from
    databases and modern data analytics frameworks (e.g.,Spark andMap Reduce) and
    build a framework with a small set of customizable network processing elements.
    To improve execution performance, NetBricks builds on safe languages and
    runtimes to provide isolation in software, rather than relying on hardware
    isolation. NetBricks provides memory isolation comparable to VMs, without the
    associated performance penalties. To provide efficient I/O, we introducea novel
    technique called zero-copy software isolation.
  feature_excerpt: >
    NetBricks is a safe and fast framework for rapid development of network
    functions for use in NFV written using Rust and DPDK. NetBricks aims to make it
    faster to develop new NFs, while also providing faster mechanisms for safely
    chaining NFs. 
  links:
    - {
        name: "Paper",
        url: "https://people.eecs.berkeley.edu/~apanda/assets/papers/osdi16.pdf",
        type: paper,
        featured: true
    }
    - {
        name: "Source Code",
        url: "https://github.com/netsys/NetBricks",
        type: code,
        featured: true
    }

- title: Quilt
  is_ongoing: false
  participants: Ethan J. Jackson, et. al
  desc: >
    Quilt aims to be the easiest way to deploy and network containers.

    Traditional container orchestrators have a procedural API focused narrowly on
    compute. The network, usually an afterthought, must be managed by a separate
    system with its own independent API. This leaves operators with a complex task:
    write a deployment script that configures everything necessary to get their
    application up and running.

    Quilt takes a different approach. It relies on a new domain specific language,
    Stitch, to specify distributed applications, independent of the specific
    infrastructure they run on. Given a stitch, Quilt can automatically deploy in a
    variety of environments: Amazon EC2, Microsoft Azure, and Google Compute Engine,
    with more coming soon. Furthermore it can do this with no setup -- just point
    Quilt at a stitch and it will take care of the rest: booting virtual machines,
    starting containers on those VMs, and ensuring they can communicate.

    Quilt is currently in alpha and under heavy development. Please try it out! We
    are eager for feedback!
  # feature_excerpt: >
    # Quilt aims to be the easiest way to deploy and network containers by relying
    # on a new domain specific language, Stitch, to specify distributed applications.
  links:
    - {
        name: "Source Code",
        url: "https://github.com/NetSys/quilt",
        type: code,
        featured: true
    }

- title: Recursively Cautious Congestion Control
  is_ongoing: false
  participants: Radhika Mittal, Justine Sherry, Sylvia Ratnasamy, Scott Shenker
  desc: >
    Any congestion control mechanism has two primary goals - to fill the pipe and to
    do no harm to other flows in the network. These two goals conflict with
    eachother – the former requires aggressiveness, whereas the latter requires
    caution. Traditional approaches use the same mechanism (the sending rate) to
    achieve these two conflicting goals. For example, TCP cautiously probes for
    bandwidth using slow-start, starting with a small initial window and then
    ramping up, in order to fill the pipe. As a result, it often takes flows several
    round-trip times to fully utilize the available bandwidth.  RC3 simply decouples
    these two goals by sending additional packets from the flow using several layers
    of low priority service, to fill the pipe, while TCP runs as usual at higher
    priority. It can therefore, quickly take advantage of available capacity from
    the very first RTT to achieve near-optimal throughputs and smaller flow
    completion times while preserving TCP-friendliness and fairness. In common
    wide-area scenarios, RC3 results in a 40% reduction in average flow completion
    times, with strongest improvements – more than 70% reduction in flow completion
    time – seen in medium to large sized (100KB - 3MB) flows.
  links:
    - {
        name: "HotNets Paper",
        url: "http://conferences.sigcomm.org/hotnets/2013/papers/hotnets-final19.pdf",
        type: paper,
    }

- title: CANDID - Classifying Assets in Networks by Determining Importance and Dependencies
  is_ongoing: false
  participants: Scott Marshall, Sylvia Ratnasamy, and Vern Paxson
  desc: >
    CANDID is a passive NetFlow-based network traffic analysis platform targeted at
    inferring relationships and dependencies among services running on hosts in
    enterprise networks. These networks present challenges of great scale,
    complexity, and nonstop dynamism, which hinder the ability for network
    administrators to maintain insight into the complex relationships that exist in
    these networks. Consequently, administrators do not always know how best to
    proceed if a network failure occurs. CANDID strives to empower administrators by
    illuminating these relationships, such that they will be prepared to remedy
    complex service failures. The solutions we present take the first steps towards
    understanding these complex in-network relationships, with a special focus on
    inferring one class of dependencies and detecting load balanced services. The
    current focal point of our work is two radically different, yet complementary,
    strategies for inferring the presence of load balancing for pairs of systems. We
    leverage a case study using real NetFlow data from the network located at
    Lawrence Berkeley National Lab to validate our strategies. Promising results
    indicate this problem space is rich with unanswered research questions and is
    worthy of further exploration.
  links:
    - {
        name: "M.S. Thesis",
        url: "http://www.eecs.berkeley.edu/Pubs/TechRpts/2013/EECS-2013-64.html",
        type: paper,
    }

- title: STS
  is_ongoing: false
  participants: Colin Scott, Andreas Wundsam, Barath Raghavan, Aurojit Panda,
    Zhi Liu, Sam Whitlock, Ahmed El-Hassany, Andrew Or, Jefferson Lai, Eugene Huang,
    Kyriakos Zarifis, and Scott Shenker
  desc: >
    Software bugs are inevitable in software-defined networking control software,
    and troubleshooting is a tedious, time-consuming task. In this paper we discuss
    how to improve control software troubleshooting by presenting a technique for
    automatically identifying a minimal sequence of inputs responsible for
    triggering a given bug, without making assumptions about the language or
    instrumentation of the software under test. We apply our technique to five open
    source SDN control platforms—Floodlight, NOX, POX, Pyretic, ONOS—and illustrate
    how the minimal causal sequences our system found aided the troubleshooting
    process.
  links:
    - {
        name: "Paper Draft",
        url: "http://www.eecs.berkeley.edu/~rcs/research/sts.pdf",
        type: paper,
    }
    - {
        name: "Stanford CTO Summit Slides",
        url: "http://www.eecs.berkeley.edu/~rcs/research/troubleshooting_with_mcses.pptx",
        type: slides,
    }
    - {
        name: "Source Code",
        url: "http://ucb-sts.github.com/sts/",
        type: code,
    }

- title: Sparrow
  is_ongoing: false
  participants: Kay Outerhout, Patrick Wendall, Matei Zaharia, Ion Stoica
  desc: >
    Sparrow is a high throughput, low latency distributed cluster scheduler. Sparrow
    is designed for applications that require frequent research allocations due to
    launching very short jobs (e.g., jobs composed of 100ms tasks). To ensure that
    scheduling does not become a bottleneck, Sparrow distributes scheduling over
    several loosely coordianted machines. Each scheduler uses a constant-time
    scheduling algorithm based on on-demand feedback acquired by probing slave
    machines. Sparrow can perform task scheduling in milliseconds, two orders of
    magnitude faster than existing approaches.
  links:
    - {
        name: "Tech Report",
        url: "http://www.pwendell.com/docs/sparrow-submission.pdf",
        type: paper,
    }
    - {
        name: "Source Code",
        url: "https://github.com/radlab/sparrow",
        type: code,
    }

- title: MegaPipe
  is_ongoing: false
  participants: Sangjin Han, Scott Marshall, Byung-Gon Chun, and Sylvia Ratnasamy
  desc: >
    BSD Sockets has been a de facto standard API for network programming. While it
    provides a simple and portable way to perform network I/O, it shows suboptimal
    performance for “message-oriented” network workloads, where connections are
    short or messages are small. This problem is exacerbated by its poor scalability
    on multi-core processors. In this work, we explore the benefits of a clean-slate
    design of network APIs aimed at achieving both high performance and ease of
    programming. We present MegaPipe, a new API for efficient, scalable network I/O,
    and evaluate its efficiency and effectiveness with a proof-of-concept
    implementation.
  links:
    - {
        name: "OSDI Paper",
        url: "http://www.eecs.berkeley.edu/~sangjin/static/pub/osdi2012_megapipe.pdf",
        type: paper,
    }

- title: DDC
  is_ongoing: false
  participants: Junda Liu, Aurojit Panda, Ankit Singla, P. Brighten Godfrey, Michael Schapira, Scott Shenker
  desc: >
    Ensuring basic connectivity in the network is generally handled by the control
    plane. However control plane convergence times are several orders of magnitude
    larger than the rate at which switches forward packets, which means that after a
    failure the network might be disrupted for a while, even though the network is
    not partitioned. Traditionally, networks have handled this problem by
    precomputing a set of backup paths, over which traffic can be redirected in the
    case of link failures. The most widely deployed example of such a mechanism is
    MPLS FRR, however MPLS fast-reroute can only handle a limited number of link
    failures. A natural question that arises is whether one could design a static
    mechanism, capable of dealing with any arbitrary set of link failures? We have
    shown that a static mechanism cannot handle an arbitrary set of failures.

    Given this result, one must rely on a dynamic mechanism to guarantee ideal
    connectivity (i.e. packets are delivered as long as a network is connected, and
    barring congestion related drops). Previous work in this area, has resulted in
    algorithms that both require unbounded space in packet headers, and NP-complete
    computations to provide this guarantee. We propose a new algorithm, Data Driven
    Connectivity, which guarantees ideal connectivity, uses a single bit in the
    packet header, and can be carried out at line rate. 
  links:
    - {
        name: "NSDI Paper",
        url: "http://eecs.berkeley.edu/~apanda/paper/nsdi13.pdf",
        type: paper,
    }

- title: APLOMB
  is_ongoing: false
  participants: Justine Sherry, Shaddi Hasan, Colin Scott, Arvind Krishnamurthy, Sylvia Ratnasamy, Vyas Sekar
  desc: >
    Middleboxes – such as firewalls, proxies, and WAN optimizers – have become
    almost ubiquitous in modern enterprises. In a survey of 57 enterprise network
    administrators, we found that these devices, while popular, are costly, error
    prone, and hard to manage. To ease these challenges, we developed APLOMB: a
    service for outsourcing middleboxes to the cloud entirely. With APLOMB,
    enterprise clients tunnel all of their Internet traffic to and from a cloud
    provider; the traffic undergoes middlebox processing at the cloud before being
    forwarded out to the Internet at large. Our implementation is built from open
    source components including Vyatta and OpenVPN; we hope to have a
    publicly-available service soon. 
  links:
    - {
        name: "SIGCOMM Paper",
        url: "http://homes.cs.washington.edu/~arvind/papers/mbox-cloud.pdf",
        type: paper,
    }

- title: NetCalls
  is_ongoing: false
  participants: Justine Sherry, Shaddi Hasan, Colin Scott, Arvind Krishnamurthy, Sylvia Ratnasamy, Vyas Sekar
  desc: >
    Modern networks deploy middleboxes to support numerous advanced processing
    capabilities such as firewalling, traffic compression, and caching. Despite the
    widespread deployment of these features, they are nevertheless invisible to the
    end hosts using the network. We designed ‘network calls’ (netcalls) to allow end
    hosts to make function calls to the network processing their traffic, allowing
    the end hosts to invoke and configure the numerous advanced features provided by
    the networks their traffic traverses. For example, we built a web server that,
    upon detecting it is under attack using application-layer knowledge, adds
    additional filters to the firewalls in its network. A key challenge to netcalls
    is that we want to allow advanced configuration to end hosts not only in their
    local network, but in any network their traffic traverses. Thus, the netcalls
    architecture lies primarily in two components: an intra-domain protocol for end
    hosts to invoke function calls with their network provider, and an inter-domain
    protocol, by which providers invoke features in each others networks on behalf
    of their clients. Source code forthcoming.
  links:
    - {
        name: "Tech Report",
        url: "http://www.eecs.berkeley.edu/Pubs/TechRpts/2012/EECS-2012-240.html",
        type: paper,
    }

- title: POX
  is_ongoing: false
  participants:
  desc: >
    POX is a Python framework for writing network control software. At its most
    minimal, it is an OpenFlow controller. It targets research and education, and
    favors ease of use over most other concerns.
  links:
    - {
        name: "Website",
        url: "http://www.noxrepo.org/",
        type: misc,
    }
    - {
        name: "Source Code",
        url: "https://github.com/noxrepo/pox",
        type: code,
    }

